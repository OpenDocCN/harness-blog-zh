# Fork/Join 框架 vs .并行流 vs. ExecutorService:终极 Fork/Join 基准| Harness

> 原文：<https://www.harness.io/blog/the-ultimate-fork-join-benchmark>

仔细看看 fork/join 框架在不同配置下的行为。

**Fork/Join 框架在不同配置下如何动作？**

围绕 Java 8 并行性有很多兴奋和批评。并行流的语法糖带来了一些严重的炒作。现在在 Java 中有许多实现并行的方法，我们想了解并行处理的性能优势和危险。经过 260 多次测试，我们从数据中获得了一些新的见解，我们想在本帖中与你分享。

## ExecutorService vs. Fork/Join 框架 vs .并行流

很久以前，在一个遥远的星系里…我的意思是，大约 10 年前，Java 中的并发只能通过第三方库实现。然后是 Java 5，引入了 java.util.concurrent 库作为语言的一部分，受到了 Doug Lea 的强烈影响。ExecutorService 变得可用，并为我们提供了一种处理线程池的简单方法。当然，java.util.concurrent 一直在发展，在 Java 7 中引入了 Fork/Join 框架，构建在 ExecutorService 线程池之上。Java 8 streams 为我们提供了一种使用 Fork/Join 的简单方法，这对于许多开发人员来说仍然有点神秘。让我们来看看他们是如何相互比较的。

我们进行了两项任务，一项是 CPU 密集型任务，另一项是 IO 密集型任务，并测试了具有相同基本功能的 4 种不同场景。另一个重要因素是我们在每个实现中使用的线程数量，所以我们也进行了测试。我们使用的机器有 8 个内核可用，因此我们有 4、8、16 和 32 个线程，以了解结果的大致走向。对于每项任务，我们还尝试了单线程解决方案，这在图表中是看不到的，因为执行时间要长得多。要了解更多关于测试的细节，尤然可以看看下面的基础部分。现在，让我们开始吧。

## 索引一个 6GB 的文件，其中包含 5.8M 行文本

在这个测试中，我们生成了一个巨大的文本文件，并为索引过程创建了类似的实现。

### 1.线程越少，CPU 就越没用，太多会增加开销

您在图表中注意到的第一件事是结果开始呈现的形状——仅从这 4 个数据点，您就可以对每个实现的行为有一个印象。这里的临界点在 8 到 16 个线程之间，因为一些线程在文件 IO 中阻塞，添加比内核更多的线程有助于更好地利用它们。当有 32 个线程时，由于额外的开销，性能会变得更差。

### 2.平行流是最好的！几乎比亚军快 1 秒:直接使用 Fork/Join

抛开语法糖(lambdas！我们没有提到 lambdas)，我们已经看到并行流比 Fork/Join 和 ExecutorService 实现的性能更好。6GB 的文本在 24.33 秒内完成索引。您可以相信 Java 能够提供最好的结果。

### 3.但是…并行流也表现最差:唯一超过 30 秒的变化

这是另一个提醒，平行流会让你慢下来。假设这发生在已经运行多线程应用程序的机器上。由于可用的线程数量较少，直接使用 Fork/Join 实际上可能比通过并行流更好——相差 5 秒，当将这两者放在一起比较时，大约有 18%的损失。

### 4.不要使用图中 IO 的默认池大小

当使用并行流的默认池大小时，机器上相同数量的内核(这里是 8 个)的性能比 16 线程版本差了将近 2 秒。使用默认的池大小要付出 7%的代价。发生这种情况的原因与阻塞 IO 线程有关。有更多的等待正在进行，所以引入更多的线程可以让我们在其他线程等待调度而不是空闲的时候从所涉及的 CPU 核心中获得更多。

如何改变并行流的默认分支/连接池大小？您可以使用 JVM 参数更改公共分支/连接池的大小:

###### [java]

###### -DJ 艾娃。util。并发。forkjoinpool。常见。并行度= 16

###### [/java]

(默认情况下，所有 Fork/Join 任务都使用一个与您的内核数量相当的公共静态池。这样做的好处是，通过在不使用线程时回收线程用于其他任务，减少了资源的使用。)

或者……您可以使用[这个技巧](http://blog.krecan.net/2014/03/18/how-to-specify-thread-pool-for-java-8-parallel-streams/)并在一个定制的 Fork/Join 池中运行并行流。这将覆盖公共 Fork/Join 池的默认使用，并允许您使用自己设置的池。相当狡猾。在测试中，我们使用了公共池。

### 5.单线程性能比最佳结果差 7.25 倍

并行性提供了 7.25 倍的改进，考虑到该机器有 8 个内核，它非常接近理论上的 8 倍预测！我们可以把剩下的归因于开销。也就是说，即使是我们测试的最慢的并行实现，这次是 4 线程并行流(30.24 秒)，其性能也比单线程解决方案(176.27 秒)高 5.8 倍。

## 当你把木卫一从等式中去掉会发生什么？检查一个数是否是质数

在下一轮测试中，我们已经完全排除了 IO，并检查了确定某个非常大的数字是否是质数需要多长时间。多大？ [19 位数字](http://t.qkme.me/3svdwh.jpg)。1，530，692，068，127，007，263，或者换句话说:1530，692，068，127，007，263 亿零 79，007，263 亿零 364，380，480，380，305，033。啊，让我透透气。无论如何，除了求平方根，我们没有使用任何优化，所以我们检查了所有偶数，即使我们的大数字没有除以 2，只是为了让它处理更长时间。剧透:这是一个质数，所以每个实现都运行相同数量的计算。

### 1.8 线程和 16 线程之间的差异较小

与 IO 测试不同，我们这里没有 IO 调用，因此 8 线程和 16 线程的性能基本相似，除了 Fork/Join 解决方案。我们实际上已经运行了几组测试，以确保我们在这里得到了良好的结果，因为这个“异常”，但它一次又一次地变得非常相似。我们很高兴在下面的评论区听到你对此的想法。

### 2.所有方法的最佳结果都是相似的

我们看到所有的实现都有一个相似的最好结果，大约 28 秒。不管我们试图用哪种方法处理它，结果都是一样的。这并不意味着我们对使用哪种方法漠不关心。查看下一个洞见。

### 3.并行流比其他实现更好地处理了线程过载

这是更有趣的部分。通过这个测试，我们再次看到运行 16 个线程的最佳结果来自于使用并行流。此外，在这个版本中，对于所有不同的线程数，使用并行流是一个很好的选择。

### 4.单线程性能比最佳结果差 4.2 倍

此外，在运行计算密集型任务时使用并行性的好处几乎是使用文件 IO 的 IO 测试的 2 倍。这是有意义的，因为这是一个 CPU 密集型测试，不像前一个测试，我们可以通过减少内核等待 IO 阻塞线程的时间来获得额外的好处。

## 结论

我建议去源代码那里学习更多关于何时使用并行流的知识，并在任何时候用 Java 进行并行处理时进行仔细的判断。最好的方法是在一个试运行环境中运行类似的测试，在那里您可以尝试更好地了解您所面临的问题。您必须注意的因素当然是您正在运行的硬件(和您正在测试的硬件)，以及您的应用程序中的线程总数。这包括公共的 Fork/Join 池和团队中其他开发人员正在开发的代码。因此，在添加您自己的并行性之前，请尽量控制这些因素，并全面了解您的应用。

## 基础

为了运行这个测试，我们使用了一个 EC2 大型实例，它有 8 个 vCPUs 和 15GB 的 RAM。一个 vCPU 意味着有超线程技术，因此实际上我们有 4 个物理内核，每个内核就像 2 个一样。就操作系统调度程序而言，我们这里有 8 个内核。为了尽可能做到公平，每个实现运行 10 次，我们取了运行 2 到 9 的平均运行时间。那是 260 次测试，唷！另一件重要的事情是处理时间。我们选择了需要 20 秒以上来处理的任务，这样差异就更容易发现，受外部因素的影响也更小。