<html>
<head>
<title>Pipeline Performance: How We Optimized With Load Tests | Harness</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>管道性能:我们如何优化负载测试</h1>
<blockquote>原文：<a href="https://www.harness.io/blog/pipeline-performance-load-tests#0001-01-01">https://www.harness.io/blog/pipeline-performance-load-tests#0001-01-01</a></blockquote><div><p>随着Harness继续以火箭般的速度增长，我们需要优化我们的平台以提高性能。我们是这样做的。</p><div fs-richtext-element="rich-text" class="blog-rtf w-richtext"><p><em>这篇关于管道性能的文章是由奈杜·安尼普、普拉尚·帕尔</em>、<em>和萨希尔·欣德瓦尼共同撰写的。</em></p><p>Harness在DevOps领域发展迅速，随着更高的增长，需要更好的可伸缩性和性能。为了满足我们快速扩大的客户群的需求，我们决定围绕管道执行的性能开展一项活动。我们开始对我们的服务执行负载测试，并在运行中进行更改，以进一步提高管道性能。这项活动的主要目标是使我们的系统更具性能和可伸缩性。</p><p>通过这些优化，我们可以:</p><ul role="list"><li>就速度和时间而言，使我们的执行更好。我们观察到性能提高了50%。</li><li>为您的执行提供了更实时的可视化。</li></ul><p>好奇我们是如何实现的吗？请继续阅读，了解更多关于我们的方法和知识。</p><h2>过程</h2><h3>估计规模</h3><p>在开始我们的性能实验之前，我们收集了一些关于我们应该达到多大规模的数据。我们计算了我们生成的构建的平均数量，我们运行的PR检查的数量，我们进行的部署的数量，以及我们与工具的任何交互。有了这个，我们可以估计一个中型组织的规模。我们推断了上述信息，并将我们的平台规模测试为当前负载的100倍。</p><p>我们的目标是以下规模:</p><ul role="list"><li>每天40万条管道。</li><li>执行期间每天5100万个事件。</li></ul><h3>是时候加些负荷了</h3><p>一旦我们的规模估算工作结束，我们决定给我们的服务增加一些负载。我们围绕一些负载测试工具做了一些分析，决定使用<a href="https://locust.io" target="_blank"> locust </a>。</p><p>除非我们有适当的监控，否则给我们的系统增加压力是没有意义的。为此，我们使用我们的<a href="https://harness.io/products/continuous-delivery/" target="_blank">连续验证</a>模块来计算服务在负载下的行为。我们还使用<a href="https://opencensus.io/" target="_blank"> Opencensus </a>发布了GCP的一些指标，帮助我们了解我们在哪些地方花费了大量时间，哪些地方可以优化。</p><p>我们用locust执行了许多活动，一次又一次地给我们的系统增加负载。每次我们执行一项新的活动，我们都会对我们的服务进行一些优化。</p><p>下面是我们监控仪表板的一些截图。</p><p>第一轮实验:</p><figure class="w-richtext-figure-type- "/><p>实验的最后一轮:</p><figure class="w-richtext-figure-type- "/><h2>学习</h2><h3>Mongo队列</h3><p>在Harness，我们的执行完全由事件驱动。在这个活动的开始，我们的事件框架是建立在遗留的mongo队列之上的。我们继承了遗留的Mongo队列，并通过围绕它构建包装器和框架，根据我们的用例对它们进行了修改。</p><p>尽管Mongo队列在过去运行得很好，但是对于我们的用例来说，由于它的存在，我们面临着一定的性能限制。这些是:</p><ul role="list"><li>由于Mongo实例上发生写冲突而导致性能下降。</li><li>Mongo队列是一个共享资源。因为我们有多个服务实例在运行，而我们只需要一个实例来处理事件，所以我们需要锁定Mongo中的事件条目。为此，我们需要更新条目，让其他实例知道这个条目正在被处理。当我们有很多实例时，这导致了太多的写冲突，从而导致一些缓慢。</li><li>从Mongo读取要慢得多，这也是我们执行时间增加的主要原因之一。</li><li>如前所述，我们需要更新mongo中的条目，让其他服务知道它是否正在被处理。由于这是一个读写操作，它只能通过主服务器，这给我们的事件带来了一些问题，因为副本/从服务器变得毫无意义。</li></ul><p>由于上述限制，Mongo并不适合我们的用例，所以我们意识到我们需要评估更多的排队系统，如Kafka、Redis Streams等。我们评估了Kafka和Redis流，但决定使用Redis流，因为它完全符合我们的用例，并且我们已经在使用它做不同的事情。</p><h3>雷迪斯</h3><p>我们总是听说没有人是完美的，雷迪斯也是如此。Redis提供了许多现成的东西，但是我们在迁移到它的时候遇到了一些问题。</p><ul role="list"><li>Redis不保证事件只处理一次。</li><li>Redis基于“至少一次”范式。通过设计。它不允许上述情况。为了实现我们的目标，我们在框架中做了一些改变，以避免两次处理相同的事件。</li><li>在Redis中，大小是一个问题，但在Mongo中不是。</li><li>Redis是一个内存存储，在内存中存储大量数据不是一个好的选择。我们的团队决定站出来，让我们的活动更轻松。</li></ul><p>我们面临上述问题，但可以成功迁移。现在，我们决定对Redis进行实验。令我们惊讶的是，我们确实观察到了巨大的性能提升。</p><p>我们在使用Redis时遇到了一些问题:</p><ul role="list"><li>如果配置不当，Redis有时会导致CPU的增加。</li><li>在基于副本的环境中，事件的顺序并不重要。如果是这样，那么事件可能不是你的最佳选择。</li></ul><h2>性能比较</h2><p>这是优化前后性能的漂亮图表。如你所见，结果令人印象深刻！</p><figure class="w-richtext-figure-type- "/><h2>结论</h2><p>针对管道性能进行优化后，我们收到了令人激动的结果。负载测试和Redis能做的事情太神奇了！您是否正在寻找高性能的CI/CD解决方案？<a href="https://app.harness.io/auth/#/signup/" target="_blank">今天带马具出去兜风</a>。</p></div></div>    
</body>
</html>