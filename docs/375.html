<html>
<head>
<title>Cloud Cost Workload Recommendations | Harness</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>云成本工作负载建议|利用</h1>
<blockquote>原文：<a href="https://www.harness.io/blog/recommendations-deep-dive#0001-01-01">https://www.harness.io/blog/recommendations-deep-dive#0001-01-01</a></blockquote><div><p>在本云成本管理建议深入探讨/教程中，了解如何根据限制和要求配置Kubernetes工作负载。</p><div fs-richtext-element="rich-text" class="blog-rtf w-richtext"><p>降低集群资源利用率的最重要方法之一是配置工作负载，在性能和成本节约之间进行权衡。反过来，这有助于我们拥有一个更小的集群，这也通过拥有更少的节点或更便宜的虚拟实例为我们节省了资金。</p><p>因此，在<a href="https://aws.amazon.com/eks/" target="_blank"> Kubernetes </a>中，拥有正确的资源请求和限制是必要的，如果您不想让您的计算资源处于饥饿状态，不想它被高内存利用率扼杀，并且想通过不过度配置来节省成本。</p><h2>什么是集装箱要求和限制？</h2><ul role="list"><li>当Pod被调度到任何节点时，请求是由Kubernetes控制平面保留的保证资源。如果节点有任何可用的资源，容器的资源利用率可以超过配置的请求。</li><li>限制是容器在其整个生命周期中允许消耗的最大资源。如果容器的内存利用率达到了极限，那么进程就会因为内存不足(OOM)而终止。然而，如果CPU利用率达到了极限，那么容器的性能就会被抑制，容器不会被杀死，而应用程序的性能仍然会受到影响。这是因为CPU是一种可压缩的资源。</li></ul><p>规格:<br/>容器:<br/> -名称:应用<br/>映像:images.my-company.example/app:v4<br/>资源:<br/>请求:<br/>内存:容器将始终提供“6Gi”#最少6GiB内存<br/> cpu:容器将始终提供“2”#最少2个vCPU】限制:<br/>内存:“10Gi”#容器不允许超过10GiB的利用率</p><p>请注意，在上面的示例中没有配置CPU的限制。这是<a href="https://cloud.google.com/blog/products/containers-kubernetes/kubernetes-best-practices-resource-requests-and-limits" target="_blank">整个行业遵循的最佳实践</a>。</p><p>这可以确保在特定时间段内，当CPU利用率超过请求的CPU时，性能不会因限制而受到影响。此外，它不会剥夺其他容器的保证CPU资源(使用请求配置)。</p><p>如果您不知道pod的实际利用率，提出适当的资源请求可能会很困难。即使你知道瞬时利用率，你也不知道它是否考虑了季节性，在利用率非常高的日子里是否足够。为此，您必须了解您的Pod在一段时间内的历史利用率数据。这将让您大致了解这段时间内的最大资源利用率。此外，如果工作负载有多个副本，并且每个副本都有不同的利用率，该怎么办？</p><p>这时，<a href="https://ngdocs.harness.io/article/o75arkcg8i-workload-recommendations" target="_blank">利用云成本工作负载建议</a>开始发挥作用，它会推荐适合该工作负载的计算资源。</p><h2>Harness如何为工作负载请求和限制提供建议</h2><p>当您使用<a href="https://ngdocs.harness.io/article/1gaud2efd4-add-a-kubernetes-cluster-connector" target="_blank"> Kubernetes连接器</a>配置<a href="https://ngdocs.harness.io/article/ltt65r6k39-set-up-cost-visibility-for-kubernetes" target="_blank">成本可见性</a>时，与连接器相关联的相应<a href="https://ngdocs.harness.io/article/2k7lnc7lvl-delegates-overview" target="_blank">委托</a>在<a href="https://kubernetes.io/docs/tasks/debug-application-cluster/resource-metrics-pipeline/#metrics-server" target="_blank">度量服务器</a>的帮助下，开始每分钟获取集群中每个节点和单元(包括单个容器)的CPU和内存资源利用率度量。</p><p>我们使用直方图聚集来收集利用率数据，并在delegate中聚集20分钟的窗口。然后，这20分钟的汇总直方图数据被发送到Harness，我们在24小时内再次汇总这些数据，并将其保存在Harness管理的数据库中。对于特定的工作负载，这些每日直方图的权重相等，因为它不是衰减直方图。因此，如果您选择汇总最近30天的数据，那么我们将对所有这些天赋予相同的权重。</p><h3><strong>为什么不是腐朽的直方图？</strong></h3><p>衰减直方图可能看起来是一个诱人的解决方案，但它没有有效地考虑到一周中某些天的高资源利用率的季节性。假设您的应用程序在周末有非常高的流量(因此有很高的资源利用率):</p><ul role="list"><li>如果您在星期五查看工作量建议并选择最后七天，那么星期六将获得最小的权重，然后是星期天，因此建议的资源将会很低。</li><li>此外，如果您在星期一查看工作负载建议，那么星期日将获得最高的权重，因此您的建议资源可能很高。</li></ul><p>这就是为什么我们在计算推荐值时，对所有以前的天数给予同等的优先权。</p><figure class="w-richtext-figure-type- "/><p>请注意，该直方图是为Pod中的每个容器计算的。此外，如果特定Pod有多个副本，则来自所有副本的数据将被视为特定容器的单独样本。换句话说，来自所有副本的利用率数据被聚合到同一个容器中。因此，所有副本的利用率数据都被标准化，并根据所选的百分比推荐合适的资源。</p><p>此外，由于建议的资源是针对每个副本的，因此在应用建议时，副本的当前数量可以保持不变。</p><figure class="w-richtext-figure-type- "/><h2>关于建议的常见问题</h2><p>当未配置资源请求和限制时，如何计算建议？</p><p>推荐的资源完全基于从指标服务器获取的利用率指标。因此，是否配置资源请求和限制并不重要，也没有什么区别。</p><p><strong>推荐会考虑CPU的突发吗？</strong></p><p>是的，我们每分钟都在收集指标数据，指标服务器发送的数据是任何容器的最后一分钟窗口的平均值。</p><p><strong>如果舱里有多个容器怎么办？</strong></p><p>在这种情况下，我们将获得针对这些单独容器的单独建议。该建议是在容器的级别，而不是在Pod的级别。</p><p><strong>建议通常建议与请求不同的限制，这会影响</strong> <a href="https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/" target="_blank"> <strong> QoS </strong> </a> <strong>。</strong></p><p>不强制严格应用建议的请求和限制。您可以使用直方图上的滑块，根据百分比值选择合适的资源，推荐的资源会相应地改变。例如，要使用有保证的QoS，您可以根据所选的百分比值为CPU和内存选择合适的资源请求，这也成为您的CPU和内存限制，因为有保证的QoS要求请求和限制应该相等。</p><p>工作负载建议只是为您提供一段时间内容器资源利用率的可见性。在它的帮助下，你可以选择一个适合你的资源。</p><h2>结论</h2><p>在这篇文章中，我们学习了如何为Kubernetes工作负载配置正确的资源。这有助于我们在集群中拥有更多可用空间，从而允许我们在同一个集群上运行更多工作负载，或者拥有一个更小的集群，最终为我们节省云成本。</p><p><br/>在我们合理调整工作负载后，在接下来的帖子中，我们将学习如何使用我们的云成本节点池建议，通过最合适的节点实例类型和节点数量来合理调整节点池。您可以参考我们的文档，了解今天的<a href="https://ngdocs.harness.io/article/x75xp0xime-node-pool-recommendations" target="_blank">节点池建议</a>。</p></div></div>    
</body>
</html>